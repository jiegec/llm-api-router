Create a LLM api router in this repo. It should support both OpenAI and Anthropic API in separate endpoints. It supports multiple API backend, with some priority order. When the high priority one failed or rate limited, use the next one automatically. The router should be written in Python. Manage your dependencies using poetry. Write tests and github CI. Git commit every time you have progress.
